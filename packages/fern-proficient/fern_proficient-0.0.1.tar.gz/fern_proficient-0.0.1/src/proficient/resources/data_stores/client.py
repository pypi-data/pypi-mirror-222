# This file was auto-generated by Fern from our API Definition.

import typing
import urllib.parse
from json.decoder import JSONDecodeError

import pydantic

from ...core.api_error import ApiError
from ...core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ...core.remove_none_from_dict import remove_none_from_dict
from ...errors.not_found_error import NotFoundError
from ...errors.unprocessable_entity_error import UnprocessableEntityError
from ...types.data_store_access_metadata import DataStoreAccessMetadata
from ...types.data_store_extended import DataStoreExtended
from ...types.data_store_identity import DataStoreIdentity
from ...types.data_store_risk_aggregation import DataStoreRiskAggregation
from ...types.get_all_external_api_v_2_data_stores_get_response import GetAllExternalApiV2DataStoresGetResponse
from ...types.get_filter_api_v_2_data_stores_filter_name_get_response import (
    GetFilterApiV2DataStoresFilterNameGetResponse,
)
from ...types.http_validation_error import HttpValidationError
from ...types.list_similar_assets_pair_response import ListSimilarAssetsPairResponse
from ...types.similar_store import SimilarStore


class DataStoresClient:
    def __init__(self, *, environment: str, client_wrapper: SyncClientWrapper):
        self._environment = environment
        self._client_wrapper = client_wrapper

    def list_data_stores(self, *, ids: typing.Union[typing.Optional[str], typing.List[str]]) -> typing.List[typing.Any]:
        """
        List all data stores.

        Parameters:
            - ids: typing.Union[typing.Optional[str], typing.List[str]].
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", "api/v2/data-stores/list"),
            params=remove_none_from_dict({"ids": ids}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[typing.Any], _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_data_stores_aggregated_by_risk(
        self, *, connector_id: typing.Optional[int] = None
    ) -> typing.List[DataStoreRiskAggregation]:
        """
        Get a summary of number of data stores, aggregated by risk.

        Parameters:
            - connector_id: typing.Optional[int].
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", "api/v2/data-stores/risk-aggregation"),
            params=remove_none_from_dict({"connector_id": connector_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[DataStoreRiskAggregation], _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_similar_stores(self, store_id: str) -> typing.List[SimilarStore]:
        """
        Get a list of all data stores similar to a specific data store.

        Parameters:
            - store_id: str.
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", f"api/v2/data-stores/{store_id}/similar"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[SimilarStore], _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_similar_store(self, store_a: str, store_b: str) -> SimilarStore:
        """
        Compare two datastores and view their common and different properties.

        Parameters:
            - store_a: str.

            - store_b: str.
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", f"api/v2/data-stores/{store_a}/similar/{store_b}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SimilarStore, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_similar_assets_by_stores(
        self,
        base_store_id: str,
        similar_store_id: str,
        *,
        filters: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        offset: typing.Optional[int] = None,
        limit: typing.Optional[int] = None,
    ) -> ListSimilarAssetsPairResponse:
        """
        Get all assets which are similar between two data stores.

        Parameters:
            - base_store_id: str.

            - similar_store_id: str.

            - filters: typing.Optional[str].

            - sort_by: typing.Optional[str].

            - offset: typing.Optional[int].

            - limit: typing.Optional[int].
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._environment}/", f"api/v2/data-stores/{base_store_id}/similar/{similar_store_id}/assets"
            ),
            params=remove_none_from_dict({"filters": filters, "sort_by": sort_by, "offset": offset, "limit": limit}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ListSimilarAssetsPairResponse, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_store_access_permissions(self, store_id: str) -> DataStoreAccessMetadata:
        """
        Get a high level overview of the number of access permissions of a specific data store.

        Parameters:
            - store_id: str.
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", f"api/v2/data-stores/{store_id}/access/metadata"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DataStoreAccessMetadata, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_store_permissible_identities(
        self, store_id: str, *, identity_name: typing.Optional[str] = None
    ) -> typing.List[DataStoreIdentity]:
        """
        List all data store identities.

        Parameters:
            - store_id: str.

            - identity_name: typing.Optional[str].
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", f"api/v2/data-stores/{store_id}/access/identities"),
            params=remove_none_from_dict({"identity_name": identity_name}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[DataStoreIdentity], _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_all_external(
        self,
        *,
        offset: typing.Optional[int] = None,
        limit: typing.Optional[int] = None,
        count_only: typing.Optional[bool] = None,
        group_by: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        filters: typing.Optional[str] = None,
    ) -> GetAllExternalApiV2DataStoresGetResponse:
        """
        List all data stores.

        Parameters:
            - offset: typing.Optional[int].

            - limit: typing.Optional[int].

            - count_only: typing.Optional[bool].

            - group_by: typing.Optional[str].

            - sort_by: typing.Optional[str].

            - filters: typing.Optional[str].
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", "api/v2/data-stores"),
            params=remove_none_from_dict(
                {
                    "offset": offset,
                    "limit": limit,
                    "count_only": count_only,
                    "group_by": group_by,
                    "sort_by": sort_by,
                    "filters": filters,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(GetAllExternalApiV2DataStoresGetResponse, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get_filter(
        self,
        name: str,
        *,
        values: typing.Optional[str] = None,
        filters: typing.Optional[str] = None,
        with_entities: typing.Optional[str] = None,
    ) -> GetFilterApiV2DataStoresFilterNameGetResponse:
        """
        Get all available filtering options for filtering on data stores.

        Parameters:
            - name: str.

            - values: typing.Optional[str].

            - filters: typing.Optional[str].

            - with_entities: typing.Optional[str].
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", f"api/v2/data-stores/filter/{name}"),
            params=remove_none_from_dict({"values": values, "filters": filters, "with_entities": with_entities}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(GetFilterApiV2DataStoresFilterNameGetResponse, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def get(self, id: str, *, with_entities: typing.Optional[str] = None) -> DataStoreExtended:
        """
        Get all information on a data store by its ID.

        Parameters:
            - id: str.

            - with_entities: typing.Optional[str].
        """
        _response = self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", f"api/v2/data-stores/{id}"),
            params=remove_none_from_dict({"with_entities": with_entities}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DataStoreExtended, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncDataStoresClient:
    def __init__(self, *, environment: str, client_wrapper: AsyncClientWrapper):
        self._environment = environment
        self._client_wrapper = client_wrapper

    async def list_data_stores(
        self, *, ids: typing.Union[typing.Optional[str], typing.List[str]]
    ) -> typing.List[typing.Any]:
        """
        List all data stores.

        Parameters:
            - ids: typing.Union[typing.Optional[str], typing.List[str]].
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", "api/v2/data-stores/list"),
            params=remove_none_from_dict({"ids": ids}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[typing.Any], _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_data_stores_aggregated_by_risk(
        self, *, connector_id: typing.Optional[int] = None
    ) -> typing.List[DataStoreRiskAggregation]:
        """
        Get a summary of number of data stores, aggregated by risk.

        Parameters:
            - connector_id: typing.Optional[int].
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", "api/v2/data-stores/risk-aggregation"),
            params=remove_none_from_dict({"connector_id": connector_id}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[DataStoreRiskAggregation], _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_similar_stores(self, store_id: str) -> typing.List[SimilarStore]:
        """
        Get a list of all data stores similar to a specific data store.

        Parameters:
            - store_id: str.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", f"api/v2/data-stores/{store_id}/similar"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[SimilarStore], _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_similar_store(self, store_a: str, store_b: str) -> SimilarStore:
        """
        Compare two datastores and view their common and different properties.

        Parameters:
            - store_a: str.

            - store_b: str.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", f"api/v2/data-stores/{store_a}/similar/{store_b}"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(SimilarStore, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_similar_assets_by_stores(
        self,
        base_store_id: str,
        similar_store_id: str,
        *,
        filters: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        offset: typing.Optional[int] = None,
        limit: typing.Optional[int] = None,
    ) -> ListSimilarAssetsPairResponse:
        """
        Get all assets which are similar between two data stores.

        Parameters:
            - base_store_id: str.

            - similar_store_id: str.

            - filters: typing.Optional[str].

            - sort_by: typing.Optional[str].

            - offset: typing.Optional[int].

            - limit: typing.Optional[int].
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(
                f"{self._environment}/", f"api/v2/data-stores/{base_store_id}/similar/{similar_store_id}/assets"
            ),
            params=remove_none_from_dict({"filters": filters, "sort_by": sort_by, "offset": offset, "limit": limit}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(ListSimilarAssetsPairResponse, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_store_access_permissions(self, store_id: str) -> DataStoreAccessMetadata:
        """
        Get a high level overview of the number of access permissions of a specific data store.

        Parameters:
            - store_id: str.
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", f"api/v2/data-stores/{store_id}/access/metadata"),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DataStoreAccessMetadata, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_store_permissible_identities(
        self, store_id: str, *, identity_name: typing.Optional[str] = None
    ) -> typing.List[DataStoreIdentity]:
        """
        List all data store identities.

        Parameters:
            - store_id: str.

            - identity_name: typing.Optional[str].
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", f"api/v2/data-stores/{store_id}/access/identities"),
            params=remove_none_from_dict({"identity_name": identity_name}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(typing.List[DataStoreIdentity], _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_all_external(
        self,
        *,
        offset: typing.Optional[int] = None,
        limit: typing.Optional[int] = None,
        count_only: typing.Optional[bool] = None,
        group_by: typing.Optional[str] = None,
        sort_by: typing.Optional[str] = None,
        filters: typing.Optional[str] = None,
    ) -> GetAllExternalApiV2DataStoresGetResponse:
        """
        List all data stores.

        Parameters:
            - offset: typing.Optional[int].

            - limit: typing.Optional[int].

            - count_only: typing.Optional[bool].

            - group_by: typing.Optional[str].

            - sort_by: typing.Optional[str].

            - filters: typing.Optional[str].
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", "api/v2/data-stores"),
            params=remove_none_from_dict(
                {
                    "offset": offset,
                    "limit": limit,
                    "count_only": count_only,
                    "group_by": group_by,
                    "sort_by": sort_by,
                    "filters": filters,
                }
            ),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(GetAllExternalApiV2DataStoresGetResponse, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get_filter(
        self,
        name: str,
        *,
        values: typing.Optional[str] = None,
        filters: typing.Optional[str] = None,
        with_entities: typing.Optional[str] = None,
    ) -> GetFilterApiV2DataStoresFilterNameGetResponse:
        """
        Get all available filtering options for filtering on data stores.

        Parameters:
            - name: str.

            - values: typing.Optional[str].

            - filters: typing.Optional[str].

            - with_entities: typing.Optional[str].
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", f"api/v2/data-stores/filter/{name}"),
            params=remove_none_from_dict({"values": values, "filters": filters, "with_entities": with_entities}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(GetFilterApiV2DataStoresFilterNameGetResponse, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def get(self, id: str, *, with_entities: typing.Optional[str] = None) -> DataStoreExtended:
        """
        Get all information on a data store by its ID.

        Parameters:
            - id: str.

            - with_entities: typing.Optional[str].
        """
        _response = await self._client_wrapper.httpx_client.request(
            "GET",
            urllib.parse.urljoin(f"{self._environment}/", f"api/v2/data-stores/{id}"),
            params=remove_none_from_dict({"with_entities": with_entities}),
            headers=self._client_wrapper.get_headers(),
            timeout=60,
        )
        if 200 <= _response.status_code < 300:
            return pydantic.parse_obj_as(DataStoreExtended, _response.json())  # type: ignore
        if _response.status_code == 404:
            raise NotFoundError(pydantic.parse_obj_as(typing.Any, _response.json()))  # type: ignore
        if _response.status_code == 422:
            raise UnprocessableEntityError(pydantic.parse_obj_as(HttpValidationError, _response.json()))  # type: ignore
        try:
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
